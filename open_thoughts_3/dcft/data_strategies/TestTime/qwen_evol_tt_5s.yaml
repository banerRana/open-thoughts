operators:
  - id: load_alpaca
    config:
      type: hf_source
      dataset: yahma/alpaca-cleaned
      split: train
  - id: evolution_prompt
    config:
      type: function
      function: data_strategies.EvolInstruct.utils.prompts_for_evolving_instructions
      function_config:
        input_instruction_column: instruction
        input_input_column: input
        output_prompt_column: instruction_evolution_prompt
    input_ids:
      - load_alpaca
  - id: sample_dataset
    config:
      type: function
      function: data_strategies.commons.uniform_sample_limited
      function_config:
        num_samples: 125  # 1.25% of 10000 target from stage 1
    input_ids:
      - evolution_prompt
  - id: evolve_instruction
    input_ids:
      - sample_dataset
    config:
      type: completions_tacc
      map: chat
      require_all_responses: false
      map_config:
        user_message_column: instruction_evolution_prompt
        output_column: evolved_instruction
      model: meta-llama/Llama-3.3-70B-Instruct
      top_p: 0.95
      batch: true
  - id: duplicate
    config:
      type: function
      function: data_strategies.TestTime.generator.duplicate_rows
      function_config:
        n_copies: 5
    input_ids:
      - evolve_instruction
  - id: annotate_instruction
    config:
      type: completions_tacc
      map: chat
      require_all_responses: false
      map_config:
        user_message_column: evolved_instruction
        output_column: completion
      model: meta-llama/Llama-3.3-70B-Instruct
      top_p: 0.95
<<<<<<< HEAD
<<<<<<< HEAD
      batch_size: 128
      batch: true
      num_vllm_instances: 1
=======
      batch_size: 768
      batch: true
>>>>>>> 6b72cc26 (working)
=======
      batch_size: 128
      batch: true
      num_vllm_instances: 1
>>>>>>> 100ad596 (should work)
    input_ids:
      - duplicate
  - id: merge_together
    config:
      type: function
      function: data_strategies.TestTime.generator.merge_duplicate_rows
      function_config:
        diff_columns: 
          - completion
    input_ids:
      - annotate_instruction
  - id: add_qwen_model
    config:
      type: gpu_function
      sharded: true
      num_shards: 4
      function: data_strategies.TestTime.qwen_prm.compute_batch_rewards
      function_config:
        steps_column: completion
        query_column: evolved_instruction
        model_name: Qwen/Qwen2.5-Math-PRM-72B
    input_ids:
      - merge_together
