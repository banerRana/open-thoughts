operators:
  - id: pool
    config:
      type: hf_source
      dataset: mlfoundations-dev/all_filtered_unverified_pdfs_pipeline
      split: train
  - id: already_annotated
    config:
      type: hf_source
      dataset: mlfoundations-dev/pdf_unverifiable_questions
      split: train
  - id: drop_columns
    config:
      type: function
      function: data_strategies.commons.keep_only_columns
      function_config:
        columns_to_keep:
          - url
          - page_number
          - improved_question_solution
          - extracted_answer_choices
          - extracted_solution
    input_ids:
        - pool
  - id: filter_out_already_annotated
    config:
      type: function
      function: data_strategies.commons.filter_dataset_if_value_exists
      function_config:
        to_filter_column: improved_question_solution
        value_column: improved_question_solution
      input_dataset_map:
        to_filter_dataset: drop_columns
        values_dataset: already_annotated
    input_ids:
      - drop_columns
      - already_annotated
  - id: sample_dataset
    config:
      type: function
      function: data_strategies.commons.uniform_sample_limited
      function_config:
        num_samples: 5000
    input_ids:
      - filter_out_already_annotated
  - id: annotate
    config:
      type: completions
      map: chat
      map_config:
        user_message_column: improved_question_solution
        output_column: r1_distill_70b_response
      model: "together_ai/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
      batch: False
      temperature: 1.0
      backend_params:
        max_requests_per_minute: 250
        max_tokens_per_minute: 500_000
        invalid_finish_reasons: [ 'content_filter' ]
      generation_params:
        max_tokens: 32_000
    input_ids:
      - sample_dataset

