operators:
- id: load_in
  config:
    type: load_preexisting
    framework_name: load_in_math_open2math
- id: annotate_gpt41_mini
  config:
    type: completions
    map: chat
    map_config:
      user_message_column: instruction_seed
      output_column: gpt41_mini_response
    model: "gpt-4.1-mini"
    batch: False
    temperature: 1.0
    require_all_responses: False
    backend_params:
      max_requests_per_minute: 4_000
      invalid_finish_reasons: ['content_filter']
  input_ids:
    - load_in
- id: get_length
  config:
    type: function
    function: data_strategies.InstructionFiltering.gemini_length_filtering.utils.get_lengths
    function_config:
      input_column: gpt41_mini_response
      output_column: length
  input_ids:
  - annotate_gpt41_mini
- id: select_to_be_used
  config:
    type: function
    function: data_strategies._B2_Filtering.utils.filter_top_n
    function_config:
      n: 31_600
      score_column: length
  input_ids:
    - get_length
- id: sample_dataset_final
  config:
    type: function
    function: data_strategies.commons.uniform_sample_fixed
    function_config:
      num_samples: 31_600
  input_ids:
  - select_to_be_used
- id: annotate
  config:
    type: completions
    map: together_qwen
    map_config:
      input_problem_column: instruction_seed
    model: Qwen/QwQ-32B
    batch: false
    backend: openai
    require_all_responses: false
    temperature: 0.999
    backend_params:
      base_url: "https://api.together.ai"
      api_key: ab025288d5a46a9a3acf23b7af22b5d824f9623cb3d62e1e69debd48291be8cc
      max_requests_per_minute: 250
      max_tokens_per_minute: 500000
      invalid_finish_reasons:
      - content_filter
    generation_params:
      max_tokens: 32000
  input_ids:
  - sample_dataset_final
- id: convert_to_sharegpt
  config:
    type: function
    function: data_strategies.commons.convert_instruction_response_to_sharegpt
    function_config:
      input_instruction_column: instruction_seed
      input_response_column: qwq_response
      output_sharegpt_column: conversations
  input_ids:
    - annotate
