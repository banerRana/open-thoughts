operators:
  - id: load_numina_math
    config:
      type: "hf_source"
      dataset: "AI-MO/NuminaMath-CoT"
      split: train
  - id: select_amc_aime
    config:
      type: function
      function: data_strategies.commons.select_rows
      function_config:
        conditions:
          source: amc_aime
    input_ids:
      - load_numina_math
  - id: keep_only_few_columns
    config:
      type: function
      function: data_strategies.commons.keep_only_columns
      function_config:
        columns_to_keep:
          - problem
          - solution
    input_ids:
      - select_amc_aime
  - id: dedup_topics
    config:
      type: function
      function: data_strategies.commons.dedup_on_columns
      function_config:
        dedup_columns:
          - problem
    input_ids:
      - keep_only_few_columns
  - id: sample_dataset
    config:
      type: function
      function: data_strategies.commons.uniform_sample_limited
      function_config:
        num_samples: 3  # NOTE: 1.25% of 8000 target from stage 1
    input_ids:
      - dedup_topics
  - id: generate_sympy_testing_code
    config: 
      type: completions
      map: chat
      model: gpt-4o-mini
      map_config:
        user_message: |
          I will give you a math problem. I want you to give me a python function using SymPy that verifies whether an answer I provide accurately solves
          that math problem. It should print "True" if correct and "False" if incorrect. Multiple inputs will be fed in through stdin spaced by \n, so make the code executable to read from stdin.
          
          Here is the math problem:
          {{problem}}

          Please provide the function and nothing else. 
        output_column: sympy_code
      temperature: 0.9  # From stage 1
      top_p: 0.5
      presence_penalty: 2.0
    input_ids:
      - sample_dataset
  - id: duplicate
    config:
      type: function
      function: data_strategies.TestTime.generator.duplicate_rows
      function_config:
        n_copies: 3
    input_ids:
      - sample_dataset
  - id: annotate
    config:
      type: completions
      map: chat
      map_config:
        user_message_column: problem
        output_column: r1_distill_70b_response
      model: "together_ai/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
      batch: False
      temperature: 1.0
      backend_params:
        max_requests_per_minute: 250
        max_tokens_per_minute: 500_000
        invalid_finish_reasons: ['content_filter']
      generation_params:
        max_tokens: 32_000
    input_ids:
      - duplicate
  - id: extract_math_answer
    config:
      type: completions
      map: metamath_extract_math_answer
      map_config:
        detailed_answer_column: r1_distill_70b_response
        output_numerical_answer_column: r1_distill_70b_extracted_answer
      model: gpt-4o-mini
    input_ids:
      - annotate
  - id: merge_together
    config:
      type: function
      function: data_strategies.TestTime.generator.merge_duplicate_rows
      function_config:
        diff_columns: 
          - r1_distill_70b_response
          - r1_distill_70b_extracted_answer
    input_ids:
      - extract_math_answer
  - id: merge
    config:
      type: merge
      join_column: problem
    input_ids:
      - merge_together
      - generate_sympy_testing_code
  - id: execute_sympy
    config:
      type: function
      function: data_strategies.MultipleSamples.sympy_executor.test_sympy
    input_ids:
      - merge
