operators:
- id: load_hf_python
  config:
    type: hf_source
    dataset: bigcode/commitpackft
    split: train
    subset: python
    trust_remote_code: True
- id: load_hf_c++
  config:
    type: hf_source
    dataset: bigcode/commitpackft
    split: train
    subset: c++
    trust_remote_code: True
- id: load_hf_java
  config:
    type: hf_source
    dataset: bigcode/commitpackft
    split: train
    subset: java
    trust_remote_code: True
- id: load_hf_c
  config:
    trust_remote_code: True
    type: hf_source
    dataset: bigcode/commitpackft
    split: train
    subset: c
- id: load_hf_c#
  config:
    trust_remote_code: True
    type: hf_source
    dataset: bigcode/commitpackft
    split: train
    subset: c#
- id: load_hf_css
  config:
    trust_remote_code: True
    type: hf_source
    dataset: bigcode/commitpackft
    split: train
    subset: css
- id: load_hf_javascript
  config:
    trust_remote_code: True
    type: hf_source
    dataset: bigcode/commitpackft
    split: train
    subset: javascript
- id: load_hf_ruby
  config:
    trust_remote_code: True
    type: hf_source
    dataset: bigcode/commitpackft
    split: train
    subset: ruby
- id: load_hf_shell
  config:
    trust_remote_code: True
    type: hf_source
    dataset: bigcode/commitpackft
    split: train
    subset: shell
- id: mix_operator
  config:
    type: mix
  input_ids:
  - load_hf_python
  - load_hf_shell
  - load_hf_c++
  - load_hf_java
  - load_hf_c
  - load_hf_c#
  - load_hf_css
  - load_hf_javascript
  - load_hf_ruby
- id: sample_dataset
  config:
    type: function
    function: data_strategies.commons.uniform_sample_limited
    function_config:
      num_samples: 40_000  # 1.25% of 10000 target from stage 1
  input_ids: ["mix_operator"]
- id: generate_instructions
  config:
    type: completions
    map: chat
    map_config:
      system_message: "You are a helpful assistant."
      user_message: |
        You are to generate a question or task for a language model based on the following instruction and code pairs. 

        Instruction: {{message}}
        Code: {{old_contents}}
        
        Include only the new question and task. Do not include anything like "Here is the instruction". Include
        the code in your question and make the task sound like what a human would ask a language model. 
      output_column: instruction_seed
    model: gpt-4o-mini
    temperature: 1.0
    batch: False
  input_ids:
    - sample_dataset
- id: add_constant_column
  config:
    type: function
    function: data_strategies.commons.add_constant_columns
    function_config:
      response_seed: ""
  input_ids:
  - generate_instructions
- id: rename_task_column
  config:
    type: function
    function: data_strategies.commons.keep_only_columns
    function_config:
      columns_to_keep:
      - response_seed
      - instruction_seed
  input_ids:
  - add_constant_column
- id: sample_dataset_pre
  config:
    type: function
    function: data_strategies.commons.uniform_sample_fixed
    function_config:
      num_samples: 40_000
  input_ids:
  - rename_task_column
- id: annotate_r1_distill_70b
  config:
    type: completions
    map: deepseek_reasoner
    map_config:
      input_problem_column: instruction_seed
    model: deepseek-reasoner
    batch: false
    temperature: 1.0
    require_all_responses: false
    backend: openai
    backend_params:
      max_requests_per_minute: 500
      max_tokens_per_minute: 1_000_000_000
      base_url: "https://api.deepseek.com/"
      invalid_finish_reasons: ['content_filter']
  input_ids:
    - sample_dataset_pre
- id: add_source_name
  config:
    type: function
    function: data_strategies.commons.add_constant_columns
    function_config:
      source: "bigcode/commitpackft"
  input_ids:
  - annotate_r1_distill_70b
- id: decontaminate
  config:
    type: cpu_function
    sharded: false
    num_cpus: 32
    function:  data_strategies._A1_Source.utils.decontaminate_fuzzy_w_ngram
    function_config:
      column: instruction_seed
      eval_datasets:
        - HuggingFaceH4/MATH-500
        - Maxwell-Jia/AIME_2024
        - AI-MO/aimo-validation-amc
        - livecodebench/code_generation_lite
        - mlfoundations-dev/AIME2025_combined
        - cais/hle
        - open-r1/codeforces
        - Idavidrein/gpqa
        - daman1209arora/jeebench
        - mlfoundations-dev/mmlu_pro_eval_full
        - Qwen/CodeElo
        - open-r1/ioi
      eval_columns:
        - problem
        - Problem
        - problem
        - question_content
        - question
        - question
        - description
        - Question
        - question
        - prompt
        - description
        - statement
      eval_splits:
        - test
        - train
        - train
        - test
        - train
        - test
        - test
        - train
        - test
        - test
        - test
        - test
      eval_subsets:
        Idavidrein/gpqa: gpqa_diamond
      similarity_threshold: 75.0
      ngram_size: 13
  input_ids:
  - add_source_name
- id: sample_dataset_final
  config:
    type: function
    function: data_strategies.commons.uniform_sample_limited
    function_config:
      num_samples: 31_600  # 1.25% of 10000 target from stage 1
  input_ids: ["decontaminate"]
- id: convert_reasoning_trace_to_final
  config:
    type: function
    function: data_strategies.commons.convert_reasoning_trace_to_final
    function_config:
      reasoning_column: reasoning
      solution_column: deepseek_solution
      output_column: final_reasoning_trace
  input_ids:
  - sample_dataset_final
- id: convert_to_sharegpt
  config:
    type: function
    function: data_strategies.commons.convert_instruction_response_to_sharegpt
    function_config:
      input_instruction_column: instruction_seed
      input_response_column: final_reasoning_trace
      output_sharegpt_column: conversations
  input_ids:
    - convert_reasoning_trace_to_final