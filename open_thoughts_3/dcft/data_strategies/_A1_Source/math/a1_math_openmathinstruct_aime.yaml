operators:
  - id: load_numina_math
    config:
      type: "hf_source"
      dataset: "AI-MO/NuminaMath-CoT"
      split: train
  - id: select_amc_aime
    config:
      type: function
      function: data_strategies.commons.select_rows
      function_config:
        conditions:
          source: amc_aime
    input_ids:
      - load_numina_math
  - id: select_olympiad
    config:
      type: function
      function: data_strategies.commons.select_rows
      function_config:
        conditions:
          source: olympiad
    input_ids:
      - load_numina_math
  - id: get_evolution_prompt
    config:
      type: function
      function: data_strategies.OpenMathInstruct.utils.create_new_prompt
      function_config:
        question_column: problem
    input_ids:
      - select_olympiad
      - select_amc_aime
  - id: generate_new_questions
    config:
      type: completions
      model: gpt-4o-mini
      map: chat
      map_config:
        user_message_column: prompt_for_new_question
        output_column: response
        output_column: instruction_seed
      temperature: 1
      batch: false
      n_repeat: 10
    input_ids: 
      - get_evolution_prompt
  

  - id: rename_task_column_final
    config:
      type: function
      function: data_strategies.commons.force_rename_columns
      function_config:
        column_maps:
          problem: instruction_seed
          solution: completion
    input_ids:
      - generate_new_questions

  - id: sample_dataset_pre
    config:
      type: function
      function: data_strategies.commons.uniform_sample_fixed
      function_config:
        num_samples: 40_000  # 1.25% of 10000 target from stage 1
    input_ids:
    - rename_task_column_final
  - id: annotate_r1
    config:
      type: completions
      map: deepseek_reasoner
      map_config:
        input_problem_column: instruction_seed
      model: deepseek-reasoner
      batch: false
      temperature: 1.0
      require_all_responses: false
      backend: openai
      backend_params:
        max_requests_per_minute: 500
        max_tokens_per_minute: 1_000_000_000
        base_url: "https://api.deepseek.com/"
        invalid_finish_reasons: ['content_filter']
    input_ids:
      - sample_dataset_pre
  - id: drop_columns
    config:
      type: function
      function: data_strategies.commons.keep_only_columns
      function_config:
        columns_to_keep:    
          - instruction_seed
          - reasoning
          - deepseek_solution
    input_ids:
    - annotate_r1
  - id: add_source_name
    config:
      type: function
      function: data_strategies.commons.add_constant_columns
      function_config:
        source: "OpenMathInstruct-AIME"
    input_ids:
    - drop_columns
  - id: decontaminate
    config:
      type: cpu_function
      sharded: false
      num_cpus: 32
      function:  data_strategies._A1_Source.utils.decontaminate_fuzzy_w_ngram
      function_config:
        column: instruction_seed
        eval_datasets:
          - HuggingFaceH4/MATH-500
          - Maxwell-Jia/AIME_2024
          - AI-MO/aimo-validation-amc
          - livecodebench/code_generation_lite
          - mlfoundations-dev/AIME2025_combined
          - cais/hle
          - open-r1/codeforces
          - Idavidrein/gpqa
          - daman1209arora/jeebench
          - mlfoundations-dev/mmlu_pro_eval_full
          - Qwen/CodeElo
          - open-r1/ioi
        eval_columns:
          - problem
          - Problem
          - problem
          - question_content
          - question
          - question
          - description
          - Question
          - question
          - prompt
          - description
          - statement
        eval_splits:
          - test
          - train
          - train
          - test
          - train
          - test
          - test
          - train
          - test
          - test
          - test
          - test
        eval_subsets:
          Idavidrein/gpqa: gpqa_diamond
        similarity_threshold: 75.0
        ngram_size: 13
    input_ids:
    - add_source_name
  - id: sample_dataset
    config:
      type: function
      function: data_strategies.commons.uniform_sample_limited
      function_config:
        num_samples: 31_600  # 1.25% of 10000 target from stage 1
    input_ids: ["decontaminate"]
  - id: convert_reasoning_trace_to_final
    config:
      type: function
      function: data_strategies.commons.convert_reasoning_trace_to_final
      function_config:
        reasoning_column: reasoning
        solution_column: deepseek_solution
        output_column: final_reasoning_trace
    input_ids:
    - sample_dataset
  - id: convert_to_sharegpt
    config:
      type: function
      function: data_strategies.commons.convert_instruction_response_to_sharegpt
      function_config:
        input_instruction_column: instruction_seed
        input_response_column: final_reasoning_trace
        output_sharegpt_column: conversations
    input_ids:
      - convert_reasoning_trace_to_final