operators:
- id: load_hf
  config:
    type: hf_source
    dataset: nvidia/OpenCodeReasoning
    subset: split_0 
    split: train
    trust_remote_code: True
- id: load_hf_2
  config:
    type: hf_source
    dataset: nvidia/OpenCodeReasoning
    subset: split_1
    split: train
    trust_remote_code: True
- id: mix
  config:
    type: mix
  input_ids:
  - load_hf
  - load_hf_2
# - id: decontaminate
#   config:
#     type: cpu_function
#     sharded: false
#     num_cpus: 16
#     function:  data_strategies._A1_Source.utils.decontaminate_fuzzy_w_ngram
#     function_config:
#       column: problem
#       eval_datasets:
#         - HuggingFaceH4/MATH-500
#         - Maxwell-Jia/AIME_2024
#         - AI-MO/aimo-validation-amc
#         - livecodebench/code_generation_lite
#         - mlfoundations-dev/AIME2025_combined
#         - cais/hle
#         - open-r1/codeforces
#         - Idavidrein/gpqa
#         - daman1209arora/jeebench
#         - mlfoundations-dev/mmlu_pro_eval_full
#         - Qwen/CodeElo
#         - open-r1/ioi
#       eval_columns:
#         - problem
#         - Problem
#         - problem
#         - question_content
#         - question
#         - question
#         - description
#         - Question
#         - question
#         - prompt
#         - description
#         - statement
#       eval_splits:
#         - test
#         - train
#         - train
#         - test
#         - train
#         - test
#         - test
#         - train
#         - test
#         - test
#         - test
#         - test
#       eval_subsets:
#         Idavidrein/gpqa: gpqa_diamond
#       similarity_threshold: 75.0
#       ngram_size: 13
#   input_ids:
#   - decompose_reasoning_trace
- id: convert_to_sharegpt
  config:
    type: function
    function: data_strategies.commons.convert_instruction_response_to_sharegpt
    function_config:
      input_instruction_column: input
      input_response_column: output
      output_sharegpt_column: conversations
  input_ids:
    - mix