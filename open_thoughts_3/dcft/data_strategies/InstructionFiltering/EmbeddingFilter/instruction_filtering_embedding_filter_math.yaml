operators:
- id: seed_math_load_in
  config:
    type: load_preexisting
    framework_name: seed_math_load_in
- id: sample_dataset
  config:
    type: function
    function: data_strategies.commons.uniform_sample_fixed
    function_config:
      num_samples: 100_000
  input_ids:
  - seed_math_load_in

- id: hf_source_numina
  config:
    type: hf_source
    dataset: AI-MO/NuminaMath-CoT
    split: train
- id: select_amc_aime
  config:
    type: function
    function: data_strategies.commons.select_rows
    function_config:
      conditions:
        source: amc_aime
  input_ids:
    - hf_source_numina
- id: select_aops
  config:
    type: function
    function: data_strategies.commons.select_rows
    function_config:
      conditions:
        source: aops_forum
  input_ids:
    - hf_source_numina
- id: rename_task_column_numina
  config:
    type: function
    function: data_strategies.commons.force_rename_columns
    function_config:
      column_maps:
        problem: question
  input_ids:
  - select_amc_aime
  - select_aops

- id: hf_source_bad_seed_math
  config:
    type: load_preexisting
    framework_name: seed_math_math_instruct
- id: rename_task_column
  config:
    type: function
    function: data_strategies.commons.force_rename_columns
    function_config:
      column_maps:
        instruction_seed: question
  input_ids:
  - hf_source_bad_seed_math

- id: calc_embeddings
  config:
    type: gpu_function
    num_gpus: 1
    num_shards: 6
    sharded: true
    function: data_strategies.commons.calc_sentence_transformers_embedding
    function_config:
      text_column: instruction_seed
      model_name: intfloat/multilingual-e5-large-instruct
  input_ids:
    - sample_dataset

- id: calc_embeddings_positive
  config:
    type: gpu_function
    num_gpus: 1
    num_shards: 1
    sharded: true
    function: data_strategies.commons.calc_sentence_transformers_embedding
    function_config:
      text_column: question
      model_name: intfloat/multilingual-e5-large-instruct
  input_ids:
    - rename_task_column_numina

- id: force_merge_shards_positive
  config:
    type: function
    function: data_strategies.commons.uniform_sample_fixed
    function_config:
      num_samples: 1_000_000
  input_ids:
  - calc_embeddings_positive

- id: calc_embeddings_negative
  config:
    type: gpu_function
    num_gpus: 1
    num_shards: 1
    sharded: true
    function: data_strategies.commons.calc_sentence_transformers_embedding
    function_config:
      text_column: question
      model_name: intfloat/multilingual-e5-large-instruct
  input_ids:
    - rename_task_column

- id: force_merge_shards_negative
  config:
    type: function
    function: data_strategies.commons.uniform_sample_fixed
    function_config:
      num_samples: 1_000_000
  input_ids:
  - calc_embeddings_negative


- id: calc_embedding_difference
  config:
    type: function
    sharded: true
    num_shards: 100
    function: data_strategies.InstructionFiltering.EmbeddingFilter.utils.calc_embedding_score
    function_config:
      embedding_column: embeddings
      positive_embedding_column: embeddings
      negative_embedding_column: embeddings
    input_dataset_map:
      dataset: calc_embeddings
      negative_dataset: force_merge_shards_negative
      positive_dataset: force_merge_shards_positive
  input_ids:
    - calc_embeddings
    - force_merge_shards_negative
    - force_merge_shards_positive
- id: select_to_be_used
  config:
    type: function
    function: data_strategies.InstructionFiltering.AskLLM.utils.filter_rank
    function_config:
      top_percentage: 0.10
      rating_column: difference_score
  input_ids:
    - calc_embedding_difference
- id: sample_dataset_final
  config:
    type: function
    function: data_strategies.commons.uniform_sample_fixed
    function_config:
      num_samples: 2_500
  input_ids:
  - select_to_be_used
- id: annotate
  config:
    type: completions
    map: chat
    map_config:
      user_message_column: instruction_seed
      output_column: r1_distill_70b_response
    model: "together_ai/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
    batch: False
    temperature: 1.0
    backend_params:
      max_requests_per_minute: 250
      max_tokens_per_minute: 500_000
      invalid_finish_reasons: ['content_filter']
    generation_params:
      max_tokens: 32_000
  input_ids:
    - sample_dataset_final
- id: convert_to_sharegpt
  config:
    type: function
    function: data_strategies.commons.convert_instruction_response_to_sharegpt
    function_config:
      input_instruction_column: instruction_seed
      input_response_column: r1_distill_70b_response
      output_sharegpt_column: conversations
  input_ids:
    - annotate
