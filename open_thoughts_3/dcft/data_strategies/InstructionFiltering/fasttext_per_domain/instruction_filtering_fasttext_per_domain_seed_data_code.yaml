operators:
- id: seed_code_load_in
  config:
    type: load_preexisting
    framework_name: seed_code_load_in


- id: get_codefeedback
  config:
    type: function
    function: data_strategies.commons.select_rows
    function_config:
      conditions:
        source: "codefeedback"
  input_ids:
    - seed_code_load_in
- id: classify_codefeedback
  config:
    type: fasttext
    num_cpus: 32
    hf_repo_id: mlfoundations-dev/instruction_filtering_fast_text_code_pos_leetcode_taco_neg_reflection_octopack
    input_column: instruction_seed
    target_label: "__label__QA_doc"
    top_percentage_ranking: 10
  input_ids:
   - get_codefeedback
- id: sample_dataset_codefeedback
  config:
    type: function
    function: data_strategies.commons.uniform_sample_fixed
    function_config:
      num_samples: 4_000
  input_ids:
  - classify_codefeedback




- id: get_glaive
  config:
    type: function
    function: data_strategies.commons.select_rows
    function_config:
      conditions:
        source: "glaive"
  input_ids:
    - seed_code_load_in
- id: classify_glaive
  config:
    type: fasttext
    num_cpus: 32
    hf_repo_id: mlfoundations-dev/instruction_filtering_fast_text_code_pos_leetcode_taco_neg_reflection_octopack
    input_column: instruction_seed
    target_label: "__label__QA_doc"
    top_percentage_ranking: 10
  input_ids:
   - get_glaive
- id: sample_dataset_glaive
  config:
    type: function
    function: data_strategies.commons.uniform_sample_fixed
    function_config:
      num_samples: 4_000
  input_ids:
  - classify_glaive



- id: get_dolphin
  config:
    type: function
    function: data_strategies.commons.select_rows
    function_config:
      conditions:
        source: "dolphin"
  input_ids:
    - seed_code_load_in
- id: classify_dolphin
  config:
    type: fasttext
    num_cpus: 32
    hf_repo_id: mlfoundations-dev/instruction_filtering_fast_text_code_pos_leetcode_taco_neg_reflection_octopack
    input_column: instruction_seed
    target_label: "__label__QA_doc"
    top_percentage_ranking: 10
  input_ids:
   - get_dolphin
- id: sample_dataset_dolphin
  config:
    type: function
    function: data_strategies.commons.uniform_sample_fixed
    function_config:
      num_samples: 4_000
  input_ids:
  - classify_dolphin



- id: get_sharegpt
  config:
    type: function
    function: data_strategies.commons.select_rows
    function_config:
      conditions:
        source: "sharegpt"
  input_ids:
    - seed_code_load_in
- id: classify_sharegpt
  config:
    type: fasttext
    num_cpus: 32
    hf_repo_id: mlfoundations-dev/instruction_filtering_fast_text_code_pos_leetcode_taco_neg_reflection_octopack
    input_column: instruction_seed
    target_label: "__label__QA_doc"
    top_percentage_ranking: 10
  input_ids:
   - get_sharegpt
- id: sample_dataset_sharegpt
  config:
    type: function
    function: data_strategies.commons.uniform_sample_fixed
    function_config:
      num_samples: 4_000
  input_ids:
  - classify_sharegpt
- id: mix
  config: 
    type: mix
  input_ids:
    - sample_dataset_glaive
    - sample_dataset_dolphin
    - sample_dataset_sharegpt
    - sample_dataset_codefeedback

- id: annotate
  config:
    type: completions
    map: chat
    map_config:
      user_message_column: instruction_seed
      output_column: r1_distill_70b_response
    model: "together_ai/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
    batch: False
    temperature: 1.0
    backend_params:
      max_requests_per_minute: 250
      max_tokens_per_minute: 500_000
      invalid_finish_reasons: ['content_filter']
    generation_params:
      max_tokens: 32_000
  input_ids:
    - mix
- id: convert_to_sharegpt
  config:
    type: function
    function: data_strategies.commons.convert_instruction_response_to_sharegpt
    function_config:
      input_instruction_column: instruction_seed
      input_response_column: r1_distill_70b_response
      output_sharegpt_column: conversations
  input_ids:
    - annotate

